# 主要实现了一个toy-browser
- code 在`./toy-browser`文件夹
# 《重学前端》浏览器是如何工作的（-）+ 扩展
## HTTP 协议
- http协议是基于tcp协议的，tcp协议是一条双向的通信通道，HTTP 在 TCP 的基础上，规定了`request-response`的模式，这个模式决定了通讯必定是由浏览器端首先发起的。toy-browser这个玩具浏览器也是基于这个原理；大部分浏览器的实现者只需要基于一个tcp库，甚至一个现成的 HTTP 库就可以搞定浏览器的网络通讯部分；HTTP 是纯粹的文本协议，它是规定了使用 TCP 协议来传输文本格式的一个应用层协议。
- 方法 options, patch, put, post, get, delete, etc.
- 状态码 https://github.com/gaoxuerong/zhihu-RESTful-api/blob/master/study-note/http/index.md
- headers 略
- HTTP Request Body
  - application/json 最常用，请求接口
  - application/x-www-form-urlencoded form表单默认
  - multipart/form-data 上传文件用这种格式
  - text/xml
## http 1.1
- https://tools.ietf.org/html/rfc2616   （1999）
- https://tools.ietf.org/html/rfc7234   （2014）
- 改进了持久连接 connection: keep-alive.(HTTP/1.1 中增加了持久连接的方法，它的特点是在一个 TCP 连接上可以传输多个 HTTP 请求，只要浏览器或者服务器没有明确断开连接，那么该 TCP 连接会一直保持。目前浏览器中对于同一个域名，默认允许同时建立 6 个 TCP 持久连接)
- HTTP 管线化
  > 持久连接虽然能减少 TCP 的建立和断开次数，但是它需要等待前面的请求返回之后，才能进行下一次请求。如果 TCP 通道中的某个请求因为某些原因没有及时返回，那么就会阻塞后面的所有请求，这就是著名的队头阻塞的问题。HTTP/1.1 中试图通过管线化的技术来解决队头阻塞的问题。HTTP/1.1 中的管线化是指将多个 HTTP 请求整批提交给服务器的技术，虽然可以整批发送请求，不过服务器依然需要根据请求顺序来回复浏览器的请求。FireFox、Chrome 都做过管线化的试验，但是由于各种原因，它们最终都放弃了管线化技术。
- 提供虚拟主机的支持
  > 在 HTTP/1.0 中，每个域名绑定了一个唯一的 IP 地址，因此一个服务器只能支持一个域名。但是随着虚拟主机技术的发展，需要实现在一台物理主机上绑定多个虚拟主机，每个虚拟主机都有自己的单独的域名，这些单独的域名都公用同一个 IP 地址。因此，HTTP/1.1 的请求头中增加了 Host 字段，用来表示当前的域名地址，这样服务器就可以根据不同的 Host 值做不同的处理。连接会一直保持。
  目前浏览器中对于同一个域名，默认允许同时建立 6 个 TCP 持久连接。
  可以使用CDN实现域名分片机制。
- 对动态生成的内容提供了完美支持
  > 在设计 HTTP/1.0 时，需要在响应头中设置完整的数据大小，如Content-Length: 901，这样浏览器就可以根据设置的数据大小来接收数据。不过随着服务器端的技术发展，很多页面的内容都是动态生成的，因此在传输数据之前并不知道最终的数据大小，这就导致了浏览器不知道何时会接收完所有的文件数据。HTTP/1.1 通过引入 Chunk transfer 机制来解决这个问题，服务器会将数据分割成若干个任意大小的数据块，每个数据块发送时会附上上个数据块的长度，最后使用一个零长度的块作为发送数据完成的标志。这样就提供了对动态内容的支持. toy-browser中就用了chunk transfer 机制；
- 在http 1.0的基础上改进了缓存问题，例如 etag.
- http 1.1 缺陷
  - 文本传输效率问题
  - header中每次都传输类似的头信息，增加了传输成本
  - 队头阻塞
    > 我们知道在 HTTP/1.1 中使用持久连接时，虽然能公用一个 TCP 管道，但是在一个管道中同一时刻只能处理一个请求，在当前的请求没有结束之前，其他的请求只能处于阻塞状态。这意味着我们不能随意在一个管道中发送请求和接收内容。
  - 同时开启了多条 TCP 连接，那么这些连接会竞争固定的带宽
  - TCP 的慢启动
    > 慢启动是 TCP 为了减少网络拥塞的一种策略，我们是没有办法改变的。之所以说慢启动会带来性能问题，是因为页面中常用的一些关键资源文件本来就不大，如 HTML 文件、CSS 文件和 JavaScript 文件，通常这些文件在 TCP 连接建立好之后就要发起请求的，但这个过程是慢启动，所以耗费的时间比正常的时间要多很多，这样就推迟了宝贵的首次渲染页面的时长了.
## HTTP 2
```
一个域名只使用一个TCP长连接来消除队头阻塞问题。
HTTP/2 使用了多路复用技术，可以将请求分成一帧一帧的数据去传输，这样带来了一个额外的好处，就是当收到一个优先级高的请求时，比如接收到 JavaScript 或者 CSS 关键资源的请求，服务器可以暂停之前的请求来优先处理关键资源的请求。
```
![HTTP/2 的多路复用](https://static001.geekbang.org/resource/image/0a/00/0a990f86ad9c19fd7d7620b2ef7ee900.jpg)
- HTTP/2 的多路复用  ![图片](https://static001.geekbang.org/resource/image/86/6a/86cdf01a3af7f4f755d28917e58aae6a.png)
  - 首先，浏览器准备好请求数据，包括了请求行、请求头等信息，如果是 POST 方法，那么还要有请求体.
  - 这些数据经过二进制分帧层处理之后，把tcp的流会被转换为一个个带有请求ID编号的帧，通过协议栈将这些帧发送给服务器。
  - 服务器接收到所有帧之后，会将所有相同 ID 的帧合并为一条完整的请求信息。
  - 然后服务器处理该条请求，并将处理的响应行、响应头和响应体分别发送至二进制分帧层。
  - 同样，二进制分帧层会将这些响应数据转换为一个个带有请求 ID 编号的帧，经过协议栈发送给浏览器。
  - 浏览器接收到响应帧之后，会根据 ID 编号将帧的数据提交给对应的请求
- 可以设置请求的优先级
  > 我们知道浏览器中有些数据是非常重要的，但是在发送请求时，重要的请求可能会晚于那些不怎么重要的请求，如果服务器按照请求的顺序来回复数据，那么这个重要的数据就有可能推迟很久才能送达浏览器，这对于用户体验来说是非常不友好的。为了解决这个问题，HTTP/2 提供了请求优先级，可以在发送请求时，标上该请求的优先级，这样服务器接收到请求之后，会优先处理优先级高的请求.
- 服务器推送
  > 其实http 2的server推送是推送的缓存，并不是真正意义上的server推送；
- 头部压缩
  > 压缩请求头和响应头,降低传输成本。
## 未来的 HTTP 3
### tcp 存在的问题
- 队头阻塞
    > 如果在数据传输的过程中，有一个数据因为网络故障或者其他原因而丢包了，那么整个 TCP 的连接就会处于暂停状态，需要等待丢失的数据包被重新传输过来。你可以把 TCP 连接看成是一个按照顺序传输数据的管道，管道中的任意一个数据丢失了，那之后的数据都需要等待该数据的重新传输.`在 TCP 传输过程中，由于单个数据包的丢失而造成的阻塞称为 TCP 上的队头阻塞。`
- TCP 建立连接的延时
### QUIC 协议
> HTTP/2 存在一些比较严重的与 TCP 协议相关的缺陷，但由于 TCP 协议僵化，我们几乎不可能通过修改 TCP 协议自身来解决这些问题，那么解决问题的思路是绕过 TCP 协议，发明一个 TCP 和 UDP 之外的新的传输协议。但是这也面临着和修改 TCP 一样的挑战，因为中间设备的僵化，这些设备只认 TCP 和 UDP，如果采用了新的协议，新协议在这些设备同样不被很好地支持。因此，HTTP/3 选择了一个折衷的方法——UDP 协议，基于 UDP 实现了类似于 TCP 的多路数据流、传输可靠性等功能，我们把这套功能称为 QUIC 协议.
HTTP/2 和 HTTP/3 协议栈
![HTTP/2 和 HTTP/3 协议栈](https://static001.geekbang.org/resource/image/0b/c6/0bae470bb49747b9a59f9f4bb496a9c6.png)
- 实现了类似 TCP 的流量控制、传输可靠性的功能。虽然 UDP 不提供可靠性的传输，但 QUIC 在 UDP 的基础之上增加了一层来保证数据可靠性传输。它提供了数据包重传、拥塞控制以及其他一些 TCP 中存在的特性。
- 集成了 TLS 加密功能。目前 QUIC 使用的是 TLS1.3，相较于早期版本 TLS1.3 有更多的优点，其中最重要的一点是减少了握手所花费的 RTT 个数。
- 实现了 HTTP/2 中的多路复用功能。和 TCP 不同，QUIC 实现了在同一物理连接上可以有多个独立的逻辑数据流（如下图）。实现了数据流的单独传输，就解决了 TCP 中队头阻塞的问题。
- 实现了快速握手功能。由于 QUIC 是基于 UDP 的，所以 QUIC 可以实现使用 0-RTT 或者 1-RTT 来建立连接，这意味着 QUIC 可以用最快的速度来发送和接收数据，这样可以大大提升首次打开页面的速度。
### HTTP/3 的挑战
- 中间设备僵化的问题。这些设备对 UDP 的优化程度远远低于 TCP，据统计使用 QUIC 协议时，大约有 3%～7% 的丢包率。
- 部署 HTTP/3 也存在着非常大的问题。因为系统内核对 UDP 的优化远远没有达到 TCP 的优化程度，这也是阻碍 QUIC 的一个重要原因。
- 服务器和浏览器端都没有对 HTTP/3 提供比较完整的支持.
## HTTPS http+TLS
  - https://tools.ietf.org/html/rfc2818
## 解析代码
  - 词（token）是如何被拆分的；（拿<p class="a">text text text</p>来说）
    - \<p
    - class="a"
    - \>
    - 文本
    - \</p>
  > token 是一个个被拆分的，实际上，我们每读入一个字符，其实都要做一次决策，而且这些决定是跟“当前状态”有关的。浏览器工程师要想实现把字符流解析成词（token），最常见的方案就是使用状态机。
  - 状态机
    - html词法状态机   https://html.spec.whatwg.org/multipage/parsing.html#tokenization